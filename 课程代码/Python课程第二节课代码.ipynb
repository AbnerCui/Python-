{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!+linux操作命令\n",
    "#!pip list\n",
    "#!pip install --upgrade pip\n",
    "#!pip install --upgrade numpy==1.15.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor, Computational graph, Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"a:0\", shape=(2, 2), dtype=float32)\n",
      "Tensor(\"add:0\", shape=(2, 2), dtype=float32)\n",
      "[[2. 4.]\n",
      " [4. 6.]]\n",
      "[[2. 4.]\n",
      " [4. 6.]]\n"
     ]
    }
   ],
   "source": [
    "#张量，计算图，会话\n",
    "import tensorflow as tf\n",
    "#三种方式定义变量\n",
    "\n",
    "a = tf.constant([[1.0, 2.0],[2.0, 3.0]], name=\"a\")\n",
    "print(a)\n",
    "b = tf.constant([[1.0, 2.0],[2.0, 3.0]], name=\"b\")\n",
    "\n",
    "result = a + b\n",
    "print(result)\n",
    "\n",
    "sess = tf.Session()\n",
    "print(sess.run(result))\n",
    "sess.close()\n",
    "\n",
    "#用这个\n",
    "with tf.Session() as sess1:\n",
    "    print(sess1.run(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1.]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "#coding:utf-8\n",
    "import tensorflow as tf\n",
    "\n",
    "g1 = tf.Graph()\n",
    "with g1.as_default():\n",
    "    #在计算图g1中定义一个变量v,并且设置初始值为0\n",
    "    v1 = tf.get_variable(name=\"v1\", initializer=tf.zeros_initializer( )(shape=[2,2]))\n",
    "    v2 = tf.get_variable(name=\"v2\", initializer=tf.zeros_initializer( )(shape=[2,2]))\n",
    "    a = tf.constant([1])\n",
    "\n",
    "g2 = tf.Graph()\n",
    "with g2.as_default():\n",
    "    # 在计算图g2中定义一个变量v,并且设置初始值为0\n",
    "    v = tf.get_variable(name=\"v\", initializer=tf.ones_initializer( )(shape=[1]))\n",
    "    b = tf.constant([0])\n",
    "\n",
    "with tf.Session(graph=g1) as sess:\n",
    "    # 运行初始化的两种方法\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    sess.run(a)\n",
    "    #这句话是什么意思？\n",
    "    with tf.variable_scope(\"\",reuse=True):\n",
    "        #通过名字获取变量\n",
    "        print(sess.run(a))\n",
    "\n",
    "with tf.Session(graph=g2) as sess:\n",
    "    # 运行初始化的两种方法\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    #tf.initialize_all_variables().run()\n",
    "\n",
    "    #这句话是什么意思？\n",
    "    with tf.variable_scope(\"\",reuse=True):\n",
    "        #通过名字获取变量\n",
    "        print(sess.run(tf.get_variable(\"v\")))\n",
    "        print(sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple NN application by TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 training steps, w is: \n",
      "[[-0.7992299]\n",
      " [ 1.493489 ]]\n",
      "After 500 training steps, w is: \n",
      "[[0.5660787]\n",
      " [1.3736113]]\n",
      "After 1000 training steps, w is: \n",
      "[[0.85490614]\n",
      " [1.1255193 ]]\n",
      "After 1500 training steps, w is: \n",
      "[[0.9535033]\n",
      " [1.0405437]]\n",
      "After 2000 training steps, w is: \n",
      "[[0.9872092]\n",
      " [1.0114942]]\n",
      "After 2500 training steps, w is: \n",
      "[[0.99873126]\n",
      " [1.001564  ]]\n",
      "After 3000 training steps, w is: \n",
      "[[1.0026709]\n",
      " [0.9981688]]\n",
      "After 3500 training steps, w is: \n",
      "[[1.0040169]\n",
      " [0.9970085]]\n",
      "After 4000 training steps, w is: \n",
      "[[1.0044775]\n",
      " [0.9966117]]\n",
      "After 4500 training steps, w is: \n",
      "[[1.0046326]\n",
      " [0.9964766]]\n",
      "After 5000 training steps, w is: \n",
      "[[1.0046859]\n",
      " [0.996431 ]]\n",
      "After 5500 training steps, w is: \n",
      "[[1.0047067]\n",
      " [0.996414 ]]\n",
      "After 6000 training steps, w is: \n",
      "[[1.0047106]\n",
      " [0.9964104]]\n",
      "After 6500 training steps, w is: \n",
      "[[1.0047106]\n",
      " [0.9964104]]\n",
      "After 7000 training steps, w is: \n",
      "[[1.0047106]\n",
      " [0.9964104]]\n",
      "After 7500 training steps, w is: \n",
      "[[1.0047106]\n",
      " [0.9964104]]\n",
      "After 8000 training steps, w is: \n",
      "[[1.0047106]\n",
      " [0.9964104]]\n",
      "After 8500 training steps, w is: \n",
      "[[1.0047106]\n",
      " [0.9964104]]\n",
      "After 9000 training steps, w is: \n",
      "[[1.0047106]\n",
      " [0.9964104]]\n",
      "After 9500 training steps, w is: \n",
      "[[1.0047106]\n",
      " [0.9964104]]\n",
      "After 10000 training steps, w is: \n",
      "[[1.0047106]\n",
      " [0.9964104]]\n",
      "After 10500 training steps, w is: \n",
      "[[1.0047106]\n",
      " [0.9964104]]\n",
      "After 11000 training steps, w is: \n",
      "[[1.0047106]\n",
      " [0.9964104]]\n",
      "After 11500 training steps, w is: \n",
      "[[1.0047106]\n",
      " [0.9964104]]\n",
      "After 12000 training steps, w is: \n",
      "[[1.0047106]\n",
      " [0.9964104]]\n",
      "After 12500 training steps, w is: \n",
      "[[1.0047106]\n",
      " [0.9964104]]\n",
      "After 13000 training steps, w is: \n",
      "[[1.0047106]\n",
      " [0.9964104]]\n",
      "After 13500 training steps, w is: \n",
      "[[1.0047106]\n",
      " [0.9964104]]\n",
      "After 14000 training steps, w is: \n",
      "[[1.0047106]\n",
      " [0.9964104]]\n",
      "After 14500 training steps, w is: \n",
      "[[1.0047106]\n",
      " [0.9964104]]\n",
      "After 15000 training steps, w is: \n",
      "[[1.0047106]\n",
      " [0.9964104]]\n",
      "After 15500 training steps, w is: \n",
      "[[1.0047106]\n",
      " [0.9964104]]\n",
      "After 16000 training steps, w is: \n",
      "[[1.0047106]\n",
      " [0.9964104]]\n",
      "After 16500 training steps, w is: \n",
      "[[1.0047106]\n",
      " [0.9964104]]\n",
      "After 17000 training steps, w is: \n",
      "[[1.0047106]\n",
      " [0.9964104]]\n",
      "After 17500 training steps, w is: \n",
      "[[1.0047106]\n",
      " [0.9964104]]\n",
      "After 18000 training steps, w is: \n",
      "[[1.0047106]\n",
      " [0.9964104]]\n",
      "After 18500 training steps, w is: \n",
      "[[1.0047106]\n",
      " [0.9964104]]\n",
      "After 19000 training steps, w is: \n",
      "[[1.0047106]\n",
      " [0.9964104]]\n",
      "After 19500 training steps, w is: \n",
      "[[1.0047106]\n",
      " [0.9964104]]\n",
      "Final w is: \n",
      " [[1.0043483]\n",
      " [0.9961435]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "BATCH_SIZE = 8\n",
    "SEED = 23450\n",
    "\n",
    "rdm = np.random.RandomState(SEED)\n",
    "X = rdm.rand(32,2)\n",
    "Y_ = [[x1 + x2 + (rdm.rand()/10.0 - 0.05)] for (x1, x2) in X]\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(None, 2))\n",
    "y_ = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "w = tf.Variable(tf.random_normal([2, 1], stddev=1, seed=1))\n",
    "y = tf.matmul(x, w)\n",
    "\n",
    "loss_mse = tf.reduce_mean(tf.square(y_ - y))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(loss_mse)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    STEPS = 20000\n",
    "    for i in range(STEPS):\n",
    "        start = (i*BATCH_SIZE) % 32\n",
    "        end = (i*BATCH_SIZE) % 32 + BATCH_SIZE\n",
    "        sess.run(train_step, feed_dict={x: X[start:end], y_: Y_[start:end]})\n",
    "        if i % 500 == 0:\n",
    "            print(\"After %d training steps, w is: \" % (i))\n",
    "            print(sess.run(w))\n",
    "    print(\"Final w is: \\n\", sess.run(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten digit recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From <ipython-input-5-cc78f702d094>:11: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "accuracy: 0.3385\n",
      "accuracy: 0.8162\n",
      "accuracy: 0.873\n",
      "accuracy: 0.896\n",
      "accuracy: 0.9035\n",
      "accuracy: 0.9067\n",
      "accuracy: 0.9101\n",
      "accuracy: 0.9104\n",
      "accuracy: 0.9119\n",
      "accuracy: 0.9129\n"
     ]
    }
   ],
   "source": [
    "#神经网络——手写数字识别\n",
    "import tensorflow as tf\n",
    "# load mnist data\n",
    "\n",
    "#使用这一行来下载代码\n",
    "#one_hot就是数据的标签形式，例如5就是5,[0,0,0,0,0,1,0,0,0,0,0]\n",
    "import tensorflow as tf\n",
    "import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "\n",
    "#下载并加载数据\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)\n",
    "\n",
    "#数据与标签的占位\n",
    "x = tf.placeholder(tf.float32,shape = [None,784])\n",
    "y_actual = tf.placeholder(tf.float32,shape=[None,10])\n",
    "\n",
    "#初始化权重和偏置\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "#softmax回归，得到预测概率\n",
    "y_predict = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "#y = 1/n[cross_entropy1,cross_entropy2,cross_entropy3][]\n",
    "#求交叉熵得到残差，reduction_indices=1以1这个维度来塌缩求交叉熵，也就是矩阵横轴这个维度\n",
    "#cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_actual*tf.log(y_predict),reduction_indices=1))\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y_predict, labels=tf.argmax(y_actual, 1))\n",
    "\n",
    "#梯度下降法使得残差最小\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "\n",
    "#测试阶段，测试准确度计算，1也是表示1这个维度，就是矩阵横轴这个维度\n",
    "correct_prediction = tf.equal(tf.argmax(y_predict,1),tf.argmax(y_actual,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,'float'))#多个批次的准确度均值\n",
    "\n",
    "#初始化值的变量还没有真正运行，只是搭建了一个计算图，使用这个方法就是运行了\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    #训练，迭代1000次\n",
    "    for i in range(1000):\n",
    "        batch_xs,batch_ys = mnist.train.next_batch(100)#按批次训练，每批100行数据\n",
    "        sess.run(train_step,feed_dict={x:batch_xs,y_actual:batch_ys})#执行训练\n",
    "        if(i%100==0):#每训练100次，测试一次\n",
    "            print(\"accuracy:\",sess.run(accuracy,feed_dict={x: mnist.test.images, y_actual: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "After 0 training step(s), validation accuracy using average model is 0.1092 \n",
      "After 1000 training step(s), validation accuracy using average model is 0.8668 \n",
      "After 2000 training step(s), validation accuracy using average model is 0.892 \n",
      "After 3000 training step(s), validation accuracy using average model is 0.9072 \n",
      "After 4000 training step(s), validation accuracy using average model is 0.9148 \n",
      "After 5000 training step(s), test accuracy using average model is 0.9184\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "INPUT_NODE = 784  # 输入节点\n",
    "OUTPUT_NODE = 10  # 输出节点\n",
    "LAYER1_NODE = 100  # 隐藏层数\n",
    "\n",
    "BATCH_SIZE = 100  # 每次batch打包的样本个数\n",
    "TRAINING_STEPS = 5000\n",
    "\n",
    "\n",
    "def train(mnist):\n",
    "    x = tf.placeholder(tf.float32, [None, 784], name='x-input')\n",
    "    y_ = tf.placeholder(tf.float32, [None, 10], name='y-input')\n",
    "    # 生成隐藏层的参数。\n",
    "    weights1 = tf.Variable(tf.truncated_normal([784, LAYER1_NODE], stddev=0.1))\n",
    "    biases1 = tf.Variable(tf.constant(0.1, shape=[LAYER1_NODE]))\n",
    "    # 生成输出层的参数。\n",
    "    weights2 = tf.Variable(tf.truncated_normal([LAYER1_NODE, 10], stddev=0.1))\n",
    "    biases2 = tf.Variable(tf.constant(0.1, shape=[10]))\n",
    "\n",
    "    # 计算不含滑动平均类的前向传播结果\n",
    "    layer1 = tf.nn.relu(tf.matmul(x, weights1) + biases1)\n",
    "    y = tf.matmul(layer1, weights2) + biases2\n",
    "\n",
    "    # 计算交叉熵及其平均值\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, 1))\n",
    "    #cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_*tf.log(y),reduction_indices=1))\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "    # 优化损失函数\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy_mean)\n",
    "\n",
    "    # 计算正确率\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    # 初始化会话，并开始训练过程。\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        validate_feed = {x: mnist.validation.images, y_: mnist.validation.labels}\n",
    "        test_feed = {x: mnist.test.images, y_: mnist.test.labels}\n",
    "\n",
    "        # 循环的训练神经网络。\n",
    "        for i in range(TRAINING_STEPS):\n",
    "            if i % 1000 == 0:\n",
    "                validate_acc = sess.run(accuracy, feed_dict=validate_feed)\n",
    "                print(\"After %d training step(s), validation accuracy using average model is %g \" % (i, validate_acc))\n",
    "\n",
    "            xs, ys = mnist.train.next_batch(50)\n",
    "            sess.run(train_step, feed_dict={x: xs, y_: ys})\n",
    "\n",
    "        test_acc = sess.run(accuracy, feed_dict=test_feed)\n",
    "        print((\"After %d training step(s), test accuracy using average model is %g\" % (TRAINING_STEPS, test_acc)))\n",
    "\n",
    "\n",
    "def main():\n",
    "    mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "    train(mnist)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
