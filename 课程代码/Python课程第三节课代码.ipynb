{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积神经网络处理mnist数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "after 0 steps the trainnig accuracy is 0.06\n",
      "after 100 steps the trainnig accuracy is 0.44\n",
      "after 200 steps the trainnig accuracy is 0.84\n",
      "after 300 steps the trainnig accuracy is 0.94\n",
      "after 400 steps the trainnig accuracy is 0.92\n",
      "after 500 steps the trainnig accuracy is 0.98\n",
      "after 600 steps the trainnig accuracy is 1\n",
      "after 700 steps the trainnig accuracy is 0.98\n",
      "test accuracy 0.98\n",
      "test accuracy 0.96\n",
      "test accuracy 0.97\n",
      "test accuracy 0.96\n",
      "test accuracy 0.94\n",
      "test accuracy 0.98\n",
      "test accuracy 1\n",
      "test accuracy 0.98\n",
      "test accuracy 0.96\n",
      "test accuracy 0.98\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784], name='x-input')\n",
    "y_ = tf.placeholder(tf.float32, [None, 10], name='y-input')\n",
    "\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "# SAME表示输入和输出是同一尺寸\n",
    "# 对于图片，因为只有两维，通常strides取[1，stride，stride，1]\n",
    "def conv2d(x, w):\n",
    "    return tf.nn.conv2d(x, w, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "# ksize是池化窗口的大小，strides是池化过程的步长\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "# 第一层卷积 前两个维度是patch的大小，接着是输入的通道数目，最后是输出的通道数目\n",
    "w_conv1 = weight_variable([5, 5, 1, 32])\n",
    "\n",
    "# 第一层卷积核的偏置项\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "# reshape中的-1表示-1代表的含义是不用我们自己指定这一维的大小，\n",
    "# 函数会自动计算，但列表中只能存在一个-1,\n",
    "# 其第2、第3维对应图片的宽、高，最后一维代表图片的颜色通道数\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, w_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# 第二层卷积层 因为第一层输出的通道数目是32 故第二层输入的通道数目也应该为32\n",
    "w_conv2 = weight_variable([5, 5, 32, 64])  # 这里的64是自己给定的,可以为其他的值\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, w_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# 全连接层,假设全连接层的个数为1024，当然也可以设置成其他值\n",
    "# 两次池化后尺寸由28*28 -> 14*14 ->7*7\n",
    "w_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "# 扁平化\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, w_fc1) + b_fc1)\n",
    "# drop_out\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# 输出层\n",
    "w_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, w_fc2) + b_fc2)\n",
    "\n",
    "# 训练和评估模型  !!!注意cross_entropy应该加负号！！\n",
    "cross_entropy = -tf.reduce_sum(y_ * tf.log(y_conv))\n",
    "# train_step=tf.train.AdamOptimizer(0.0001).minimize(cross_entropy)\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_, 1), tf.argmax(y_conv, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "#x - input\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for i in range(800):\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        if i % 100 == 0:\n",
    "            train_accuracy = sess.run(accuracy, feed_dict={x: batch[0]\n",
    "                , y_: batch[1], keep_prob: 1.0})\n",
    "            print(\"after %d steps the trainnig accuracy is %g\" % (i, train_accuracy))\n",
    "        sess.run(train_step, feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "    # print(sess.run(accuracy,feed_dict={x:mnist.test.images,y_:mnist.test.labels,keep_prob:1.0}))\n",
    "\n",
    "    for i in range(10):\n",
    "        testSet = mnist.test.next_batch(100)\n",
    "        print(\"test accuracy %g\" % accuracy.eval(feed_dict={x: testSet[0], y_: testSet[1], keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
